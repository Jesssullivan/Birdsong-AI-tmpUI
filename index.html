<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>Quick Sound Annotator</title>

        <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">

        <!-- Leaflet core CSS -->
        <link rel="stylesheet" href="https://unpkg.com/leaflet@1.6.0/dist/leaflet.css" integrity="sha512-xwE/Az9zrjBIphAcBb3F6JVqxf46+CDLwfLMHloNu6KEQCAWi6HcDUbeOfBIptF7tcCzusKFjFw2yuvEpDL9wQ==" crossorigin=""/>

        <!-- Leaflet Draw CSS -->
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet.draw/1.0.3/leaflet.draw.css"/>

        <script src="https://kit.fontawesome.com/73cd972fdf.js" crossorigin="anonymous"></script>

        <style>

            /*
            * Make the leaflet holder long and narrow for the spectrogram.
            */
            .leaflet-image-holder{
                height: 250px!important;
                width: 1200px!important;
            }

            /*
            * The vertical line for the audio position.
            */
            .leaflet-image-holder:before {
                content:"";
                width:3px;
                height:100%;
                display:block;
                z-index: 1000;
                left:50%;
                position:absolute;
                background-image: linear-gradient(rgb(179, 0, 0), rgb(179, 0, 0));
                background-size: 3px 100%;
                background-repeat: no-repeat;
                background-position: center center;
            }

            /*
            * The vertical 1 second lines. 240 here is an assumption that about 5 seconds of audio are visible in 1200 px (ie. 240 = 1200 / 5)
            */
            /*
            .leaflet-image-holder:after {
                content:"";
                width:100%;
                height:100%;
                display:block;
                z-index: 1000;
                position:absolute;
                background-image: repeating-linear-gradient(-90deg,
                transparent 1px,
                transparent 240px,
                rgba(179, 0, 0, 0.308) 1px 241px);
            }
            */
            /*
            This version offsets the lines by 0.5 seconds so that they overlap with the audio position line.
            NOTE: these have to be "under" the leaflet map so that they don't intercept mouse events.
                  so the zindex needs to be smaller than the leaflet map.
            NOTE V2: This has been updated to add span elements after the creation of the leaflet map. See below.
            */
            /* .leaflet-image-holder:after {
                content:"";
                width:100%;
                height:100%;
                display:block;
                z-index: 200;
                position:absolute;
                background-image: repeating-linear-gradient(
                    -90deg,
                    transparent,
                    transparent 120px,
                    #49505759 120px,
                    #49505759 121px,
                    transparent 122px ,
                    transparent 240px
                )
            } */


            .annotation-instance-category-name{
                font-size: small;
            }

            .annotation-instance-supercategory-name{
                font-size: small;
            }

        </style>

    </head>
    <body>
        <div class="container-fluid">

            <!-- Directory Chooser, Instructions, and Configurations -->
            <div id="dirChooser">
                <div class="row justify-content-md-center">
                    <div class="col-md-4">
                        <h1> Quick Sound Annotator </h1>
                    </div>
                </div>
                <div class="row justify-content-md-center mb-5">
                    <div class="col-md-4">
                        <form>

                            <div class="form-group">

                                <!-- Provide easy access category ids -->
                                <label for="easyAccessCategories">Quick Access Category IDs</label>
                                <textarea class="form-control" id="easyAccessCategories" rows="5" aria-describedby="easyAccessCategoriesHelpBlock"></textarea>
                                <small id="easyAccessCategoriesHelpBlock" class="form-text text-muted">
                                    Provide the category ids, one per line, that you would like quick access to when adding new instances. This is convenient when the total number of categories is large, but the current annotation task is for a small subset of categories.
                                </small>

                                <!-- Should the category ids be interpreted as strings or integers? -->
                                <div class="custom-control custom-radio custom-control-inline" aria-describedby="categoryIDTypeHelpBlock">
                                    <input type="radio" id="categoryIDTypeRadioStr" name="categoryIDTypeRadio" class="custom-control-input" checked>
                                    <label class="custom-control-label" for="categoryIDTypeRadioStr">String IDs</label>
                                  </div>
                                  <div class="custom-control custom-radio custom-control-inline">
                                    <input type="radio" id="categoryIDTypeRadioInt" name="categoryIDTypeRadio" class="custom-control-input">
                                    <label class="custom-control-label" for="categoryIDTypeRadioInt">Integer IDs</label>
                                </div>
                                <small id="categoryIDTypeHelpBlock" class="form-text text-muted">
                                    Should the category ids be converted to integers, or left as strings, when matching with the category ids found in <code>categories.json</code>?
                                </small>

                            </div>


                            <!-- Browse button to let the user choose the annotation directory -->
                            <div class="custom-file mt-3">
                                <input type="file" class="custom-file-input" id="customFile" webkitdirectory="" directory="">
                                <label class="custom-file-label" for="customFile">Choose a directory</label>
                            </div>
                        </form>
                    </div>
                </div>
                <hr>
                <div class="row">
                    <div class="col-md-4">
                        <h3>About</h3>
                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <p>This is a tool to annotate images with boxes and category labels. The utility of this tool is that you don't need to run a server, you can create the annotations on your local machine. Once you have finished annotating the images, you can download the annotations and use them to train or evaluate a machine learning system.</p>
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-4">
                        <h3>Prerequisites</h3>
                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <ol>
                            <li>
                                This tool requires the Google Chrome Browser.
                            </li>
                            <li>
                                Image files should be jpegs or pngs.
                            </li>
                        </ol>
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-4">
                        <h3>Quick Start with Example Data</h3>
                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <ol>
                            <li>
                                Annotate a bird photo and a spectrogram image by clicking the <kbd>Browse</kbd> button above and choosing the <strong>annotation_task</strong> folder &#128193;, found in the same directory as this <code>index.html</code> file.
                                <ul>
                                    <li>Note, you should select the <strong>annotation_task</strong> folder &#128193;, not an individual file.</li>
                                </ul>
                            </li>
                        </ol>
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-4">
                        <h3>Instructions for Customizing</h3>
                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <ol>
                            <li>
                                Create a folder in the same directory as the <code>index.html</code> file, call it <strong>annotation_task</strong>.
                                <ul>
                                    <li>
                                        <code>index.html</code> is <strong>this file</strong>, the one you are currently reading.
                                    </li>
                                    <li>
                                        The name <strong>annotation_task</strong> is not required, call the directory whatever you'd like. It just needs to be in the same directory as <code>index.html</code>.
                                    </li>
                                </ul>
                            </li>
                            <li>
                                Inside the <strong>annotation_task</strong> folder, create a JSON file called <code>categories.json</code>
                                <ul>
                                    <li>
                                        This file should contain the list of categories you would like to annotate, having the following format:
                                        <pre><code>
                                            [{
                                                "id" : 1,
                                                "name" : "Bird",
                                                "supercategory" : "Animal"
                                            },
                                            {
                                                "id" : 2,
                                                "name" : "Man",
                                                "supercategory" : "Person"
                                            },
                                            {
                                                "id" : 3,
                                                "name" : "Bicycle",
                                                "supercategory" : "Machine"
                                            },...]
                                        </code></pre>
                                    </li>
                                </ul>
                            </li>
                            <li>
                                Add images to the <strong>annotation_task</strong> folder in one of two ways:
                                <ol>
                                    <li>Simply inlcude jpeg or png image files. The image name (without the file extension) will be used as the image id. You can place these in their own directory (e.g. <strong>annotation_task/images</strong>)</li>
                                    <li>
                                        Create a JSON file called <code>images.json</code>, containing a list of images to annotate, having the following format:
                                        <pre><code>
                                            [{
                                                "id" : "2044008b9b424bf98d1635251a0802c8",
                                                "url" : "https://s3.amazonaws.com/vibe-content/photos/2044008b9b424bf98d1635251a0802c8.jpg"
                                            },...]
                                        </code></pre>
                                    </li>
                                    <li>
                                        You cannot have both image files and a <code>images.json</code>. It must be one or the other.
                                    </li>
                                </ol>
                            </li>
                            <li>
                                OPTIONAL: If you have an existing annotation file for the images you will annotate, then you can include it in the <strong>annotation_task</strong> folder. It must be named <code>annotations.json</code>.
                            </li>
                            <li>
                                OPTIONAL: Configure the tool using the options found at the top of the page.
                            </li>
                            <li>
                                Start annotating the images by clicking the <kbd>Browse</kbd> button above and choosing the <strong>annotation_task</strong> folder &#128193;.
                                <ul>
                                    <li>Note, you should select the <strong>annotation_task</strong> folder &#128193;, not an individual file.</li>
                                    <li>The browser will ask your permission to "upload" the files. Click the <kbd>Upload</kbd> button.</li>
                                    <li>If the images don't render, then make sure that the <strong>annotation_task</strong> folder is in the same directory as <code>index.html</code>.</li>
                                </ul>
                            </li>
                            <li>
                                Once you have finished annotating, you can scroll to the bottom of the page and press the <kbd>Export Annotations</kbd> button to download an <code>annotations.json</code> file.
                                <ul>
                                    <li>You can copy and paste the <code>annotations.json</code> file from your downloads folder to the <strong>annotation_task</strong> folder in order to review or edit your annotations at a later time.</li>
                                </ul>
                            </li>
                        </ol>
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-4">
                        <h3>Tips and Tricks</h3>
                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <ul>
                            <li>
                                After drawing one box on an image, you can right click to duplicate that box at the current cursor location. This is convenient when annotating several instances of the same category.
                            </li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- This is where the Leaflet Annotators will go -->
            <div id="annotationTask" hidden>

                <div class="row justify-content-center">
                    <div class="col-md-3 alert-primary">
                        <div class="row">
                            <div class="col">
                                <h4 id="currentImageProgress">Image 0 / 0</h4>
                            </div>
                            <div class="col">
                                <h4 id="currentAudioDuration"></h4>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-3">
                        <button id="previousImageButton" type="button" class="btn btn-primary" disabled>Previous</button>
                        <button id="nextImageButton" type="button" class="btn btn-primary" disabled>Next</button>
                    </div>
                    <div class="col-md-3">
                        <div class="input-group">
                            <div class="input-group-prepend">
                                <button class="btn btn-outline-primary" type="button" id="goToImageButton">Go To File</button>
                            </div>
                            <input id="goToImageInput" type="text" class="form-control">
                        </div>
                    </div>
                    <div class="col-md-3">
                        <button id="exportAnnos" type="button" class="btn btn-primary">Export Annotations</button>
                    </div>
                </div>

                <!-- <div class="row justify-content-end">
                    <div class="col-md-3">
                        <button id="exportAnnos" type="button" class="btn btn-primary">Export Annotations</button>
                    </div>
                </div> -->

                <div id="annotationHolder"></div>

                <!-- <div class="row justify-content-md-center">
                    <div class="col-md-1"><p id="currentImageProgress">Image 0 / 0</p></div>
                    <div class="col-md-2">
                        <button id="previousImageButton" type="button" class="btn btn-primary" disabled>Previous</button>
                        <button id="nextImageButton" type="button" class="btn btn-primary" disabled>Next</button>
                    </div>
                </div>
                <div class="row justify-content-md-center">
                    <div class="col-md-1">
                        <div class="form-group">

                            <label for="goToImageInput">Go to image:</label>
                            <input id="goToImageInput" type="text" class="form-control form-control-sm">

                            <button id="goToImageButton" type="button" class="btn btn-primary">Go</button>
                        </div>
                    </div>
                </div> -->


            </div>

            <div class="row">
                <div class="col-md-8">
                    <h5>Basic Instructions (Detailed Protocol <a target="_blank" href="https://docs.google.com/presentation/d/1oGLLsKCFEC1-SaoZhvWRLDR29Kt39d5obtVTtG3UGvo/edit#slide=id.p">Here</a>)</h5>
                    <ul class="list-group-flush">
                        <li class="list-group-item"><strong>Annotate 5-10 vocalizations</strong> of the target species per audio file. When possible, annotate diverse vocalizations (song variation, calls, overlaps with other acoustic events, etc.).</li>
                        <li class="list-group-item"><strong>Annotate around each target.</strong> For each annotation of the target species, also annotate all other natural sounds visible in the editor when the target species vocalization is centered. Use the arrow keys (or Focus button) to center the target box at the dark red line in the middle of the spectrogram window. Then annotate all other vocalizations in the window.</li>
                        <li class="list-group-item"><strong>Unknown birds</strong> - Use “Unknown Bird” if you are not sure of the identification, but try to identify the bird if you can! A labeled box is more valuable than “unknown.”</li>
                        <li class="list-group-item"><strong>Mammal and amphibians</strong> - Also annotate mammals and amphibians when they are in the 5 second window of a target species annotation. Use “Unknown Animal” if you are not sure of the species, or if the species is not an option when you search.</li>
                        <li class="list-group-item"><strong>Separate vocals with >1s of spacing.</strong> If there is at least one second of space between vocalizations, annotate them separately. The faint vertical lines are one second apart.</li>
                        <li class="list-group-item"><strong>Frequency and time are both important</strong>, make the box tight to the vocalization (include harmonics).</li>
                        <li class="list-group-item"><strong>Background Boxes</strong> - When possible, annotate a "Background No Bird" box that is at least one second long and doesn't contain any animal vocalizations. These boxes allow us to learn how to separate ambient background noise and animal vocalizations.</li>
                        <li class="list-group-item"><strong>Annotations are saved when you click Next or Previous</strong> or use the Go To File option. You can close the window or reload if you want to revert any changes you made</li>
                    </ul>
                </div>
            </div>

            <div class="row mt-5">
                <div class="col-md-4">
                    <h5>Audio & Spectrogram Controls</h5>
                    <ul class="list-group-flush">
                        <li class="list-group-item"><strong>Space Bar</strong>: play and pause</li>
                        <li class="list-group-item"><strong>Left Arrow</strong>: move backward (hold the key to scroll backward)</li>
                        <li class="list-group-item"><strong>Right Arrow</strong>: move forward (hold the key to scroll forward)</li>
                        <li class="list-group-item"><strong>Right Click</strong> (or ctrl-Click):  create a new annotation at the cursor using the same species, frequency and time duration as the last annotation you made.</li>
                    </ul>
                </div>
            </div>

        </div>

        <!-- jQuery first, then Popper.js, then Bootstrap JS -->
        <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

        <!-- Load React. -->
        <script src="https://unpkg.com/react@16/umd/react.development.js" crossorigin></script>
        <script src="https://unpkg.com/react-dom@16/umd/react-dom.development.js" crossorigin></script>

        <!-- Our App javascript file -->
        <script src="leaflet.annotation.js"></script>

        <script type="text/javascript">

            // global variables that we'll need access to in a few functions
            let annotatorRendered = null; // allows us to export annotations
            let currentImageIndex = 0; // keep track of which image we are working on.


            // Dimensions of the spectrogram
            let spectrogram_height = null;
            let spectrogram_width = null;

            // This value helps dictate the "window size" for the spectrogram. Assuming the Leaflet Map is 1200px wide:
            // A 220 original height spectrogram, scaled up to 300 results in ~3.5 seconds
            // A 220 original height spectrogram, scaled down to 211 results in ~5 seconds
            let targetSpectrogramHeight = 211; //300; // the height that the spectrogram should be rendered at.

            // Audio Controls
            // space bar is play and pause
            let pixels_per_second = null;
            let pixels_per_ms = null;
            let pan_interval_ms = 100; // the interval that we should pan the spectrogram at.

            let audioElement = null;
            let playing_audio = false;
            let playing_audio_timing_id = null;
            let current_offset = 0; // our current pixel offset in the image

            let arrow_key_distance = 250. / 4; // quarter of a second movement (assuming 250 pixels per second...)

            function panSpectrogram() {

                let currentTime = audioElement.currentTime;

                // Where is the audio in milliseconds
                //let audio_time_ms = currentTime * 1000;

                // Convert milliseconds to pixel translation
                //let offset = pixels_per_ms * audio_time_ms;

                let offset = pixels_per_second * currentTime;

                //console.log(currentTime, offset);

                annotatorRendered.panTo(offset);

                current_offset = offset;

            }

            function audioEnded(){
                clearInterval(playing_audio_timing_id);
                playing_audio = false;
            }

            function startPlaying(){

                if(audioElement != null){

                    let offset_in_seconds = current_offset / pixels_per_second;
                    audioElement.currentTime = offset_in_seconds;

                    //console.log(current_offset);
                    //console.log(offset_in_seconds);

                    // If the user "focused" on an annotation, then our offset position that is rendered is off.
                    // So make sure to "re-pan" the map to the current offset.
                    annotatorRendered.panTo(current_offset);

                    audioElement.onended = audioEnded;
                    audioElement.play();
                    playing_audio_timing_id = setInterval(panSpectrogram, pan_interval_ms);
                    //audioElement.ontimeupdate = (e) => { panSpectrogram() };
                    playing_audio = true;

                    // audioElement.onplaying = (event) => {
                    //     console.log("onplaying");
                    //     playing_audio_timing_id = setInterval(panSpectrogram, pan_interval_ms);
                    // };
                }

            }

            function stopPlaying(){

                if(audioElement != null && !audioElement.paused){

                    audioElement.pause();
                    clearInterval(playing_audio_timing_id);

                }
                playing_audio = false;

            }

            function goForward(){

                if(current_offset >= spectrogram_width){
                    return;
                }

                if (playing_audio){
                    stopPlaying();
                }

                current_offset = Math.min(spectrogram_width, current_offset + arrow_key_distance);
                annotatorRendered.panTo(current_offset);

            }

            function goBackward(){

                if(current_offset == 0){
                    return;
                }

                if (playing_audio){
                    stopPlaying();
                }

                current_offset = Math.max(0, current_offset - arrow_key_distance);
                annotatorRendered.panTo(current_offset);

            }

            /* Handle the situation when the map pans to an annotation.
            In this case we need to change our audio playback position.
            */
            function mapPannedTo(x_loc){

                if (playing_audio){
                    stopPlaying();
                }

                // Convert the pixel location to time
                let audio_pos = x_loc / pixels_per_second;
                // Set the playback position in the audio
                audioElement.currentTime = audio_pos;
                // Set our current offset
                current_offset = x_loc;

            }

            function handleKeyDown(e){

                let SPACE_KEY = 32;
                let PLAY_PAUSE_KEY = SPACE_KEY;
                let RIGHT_ARROW_KEY = 39; // Forward
                let LEFT_ARROW_KEY = 37; // Backward

                switch(e.keyCode){
                    case PLAY_PAUSE_KEY:
                        if (e.target == document.body){
                            if(playing_audio){
                                stopPlaying();
                            }
                            else{
                                startPlaying();
                            }
                            e.preventDefault(); // prevent the space button from scrolling
                        }
                        break;
                    case RIGHT_ARROW_KEY:
                        goForward()
                        break;
                    case LEFT_ARROW_KEY:
                        goBackward()
                        break;
                }

            }

            function enableAudioKeys(){
                // Register keypresses
                document.addEventListener("keydown", handleKeyDown);
            }

            function disableAudioKeys(){
                // Unregister keypresses
                document.removeEventListener("keydown", handleKeyDown);
            }


            function startAnnotating(images_data, categories, annotations, config){

                if (images_data.length == 0){
                    alert("Error: No images?");
                    return;
                }

                // Parse the config dict
                console.log(config);
                let quickAccessCatIDs = config.quickAccessCategoryIDs || [];
                let annotation_file_prefix = config.annotationFilePrefix || "";


                // Group the annotations by image_id so that we can easily overwrite them with the new annotations
                image_id_to_annotations = {};
                images_data.forEach(image_info => {
                    image_id_to_annotations[image_info['id']] = [];
                })
                annotations.forEach(anno => {
                    let image_id = anno['image_id'];
                    image_id_to_annotations[image_id].push(anno);
                });


                function annotateImage(imageIndex){

                    let image_info = images_data[imageIndex];
                    let existing_annotations = image_id_to_annotations[image_info.id];

                    if(annotatorRendered != null){
                        // There was a previous image, make sure to unmount it (and stop audio)

                        stopPlaying();
                        disableAudioKeys();
                        ReactDOM.unmountComponentAtNode(document.getElementById("annotationHolder"));
                        annotatorRendered = null;

                    }
                    $("#currentImageProgress").text('Image ' + (imageIndex + 1) + ' / ' + images_data.length);
                    $("#currentAudioDuration").text('Dur: ? sec');
                    if(imageIndex == 0){
                        $("#previousImageButton").prop("disabled", true);
                    }
                    else{
                        $("#previousImageButton").prop("disabled", false);
                    }

                    if(imageIndex == images_data.length - 1){
                        $("#nextImageButton").prop("disabled", true);
                    }else{
                        $("#nextImageButton").prop("disabled", false);
                    }


                    // Create an image element and load in the pixels
                    let imageEl = new Image();
                    // We need to have access to the pixels before initializing Leaflet
                    imageEl.onload = function(){

                        // Get the dimensions of the spectrogram
                        spectrogram_height = imageEl.height;
                        spectrogram_width = imageEl.width;

                        function addAudioFunctions(annotatorRendered){

                            // Setup the view for the audio
                            annotatorRendered.renderForSpectrogram(targetSpectrogramHeight);
                            annotatorRendered.turnOffZoom();
                            annotatorRendered.turnOffDrag();

                            // Audio Controls
                            // space bar is play and pause
                            pixels_per_second = null;
                            pixels_per_ms = null;

                            audioElement = new Audio();
                            playing_audio = false;
                            playing_audio_timing_id = null;
                            current_offset = 0;

                            // Load in the audio for the spectrogram
                            audioElement.addEventListener('canplaythrough', () => {
                                let duration = audioElement.duration;
                                // The duration variable now holds the duration (in seconds) of the audio clip

                                // This should be ~250 (because of the SoX command)
                                pixels_per_second = 250.0; //spectrogram_width / duration;

                                pixels_per_ms = pixels_per_second / 1000.0;

                                console.log("Spectrogram Height: " +  spectrogram_height);
                                console.log("Spectrogram Width: " +  spectrogram_width);
                                console.log("Duration " + duration);
                                console.log("Pixels / second : " + pixels_per_second);
                                console.log("Pixels / milisecond : " + pixels_per_ms);
                                console.log("Current Time " + audioElement.currentTime);

                                enableAudioKeys();

                                $("#currentAudioDuration").text('Dur: ' + duration.toFixed(2) + ' sec');

                            });
                            audioElement.src = image_info.audio;
                            audioElement.addEventListener('error', () => {
                                alert("Error loading the audio for image " + image_info.id + ". Perhaps the resouce has been deleted? Maybe skip or try to come back to this asset?");
                            });
                            audioElement.load();

                        }

                        function delayAudioPrepTillRender(annotatorRendered){

                            if (!('audio' in image_info)){
                                console.log("No audio url in image info");
                                return;
                            }

                            // Annoying, but we need leaflet to render the image before we start
                            // doing transformations
                            setTimeout(()=>addAudioFunctions(annotatorRendered), 100);
                        }

                        // Create the Leaflet.annotation element
                        let annotator = React.createElement(document.LeafletAnnotation, {
                            imageElement : imageEl,
                            image : image_info,
                            annotations : existing_annotations,
                            categories : categories,
                            options : {
                                enableEditingImmediately : true,

                                map : {
                                    attributionControl : false,
                                    zoomControl : false,
                                    boxZoom : false,
                                    doubleClickZoom : false,
                                    keyboard : false,
                                    scrollWheelZoom : false
                                },

                                quickAccessCategoryIDs : quickAccessCatIDs,

                                newInstance: {
                                    annotateCategory: true,
                                    annotateSupercategory: false,
                                    annotationType: 'box'
                                },

                                duplicateInstance : {
                                    enable : true,
                                    duplicateY : true  // duplicate the frequcy components of the box
                                },

                                showCategory : true,
                                showSupercategory: true,
                                showIsCrowdCheckbox: false,

                                enableBoxEdit : true,
                                renderBoxes : true,

                                enableSegmentationEdit : false,
                                renderSegmentations : false,

                                imageInfoComponent : document.MLAudioInfo,

                                didMountLeafletCallback : delayAudioPrepTillRender,
                                didFocusOnAnnotationCallback : mapPannedTo
                            }
                        }, null);

                        // Render the annotator
                        annotatorRendered = ReactDOM.render(annotator, document.getElementById('annotationHolder'));


                        // Create the one second intervals lines that will appear over the spectrogram.
                        // These are 1px wide lines.
                        // NOTE: these values are hard coded for a window width of 1200px with one second being 240px.
                        let interval_offset = 120;
                        let one_second_interval = 240;
                        for(let i = 0; i < 5; i++){
                            $(".leaflet-image-holder").append(
                                $("<span></span>").css({
                                    "content" : "",
                                    "width": "1px",
                                    "height": "100%",
                                    "display": "block",
                                    "z-index": 999,
                                    "left": "" + (interval_offset + (i * one_second_interval)) + "px",
                                    "position": "absolute",
                                    "background-image": "linear-gradient(#495057bf, #495057bf)",
                                    "background-size": "1px 100%",
                                    "background-repeat": "no-repeat",
                                    "background-position": "center center"
                                })
                            );
                        }


                    }
                    imageEl.addEventListener('error', () => {
                        alert("Error loading the pixels for image " + image_info.id + ". Perhaps the resouce has been deleted? Maybe skip?");
                    });
                    imageEl.src = image_info.url;

                }

                function saveCurrentAnnotations(){

                    // It could be the case that the image or audio failed to load, in which case we wouldn't have a `annotatorRendered`
                    if (annotatorRendered != null){
                        let annos = annotatorRendered.getAnnotations({
                            modifiedOnly : false,
                            excludeDeleted : true
                        });

                        let image_id = images_data[currentImageIndex].id;
                        image_id_to_annotations[image_id] = annos;
                    }
                }


                $("#nextImageButton").click(function(){

                    saveCurrentAnnotations();

                    if(currentImageIndex < images_data.length - 1){
                        currentImageIndex += 1;
                        annotateImage(currentImageIndex);
                    }

                    document.getElementById("nextImageButton").blur();

                });

                $("#previousImageButton").click(function(){

                    saveCurrentAnnotations();

                    if(currentImageIndex > 0){
                        currentImageIndex -= 1;
                        annotateImage(currentImageIndex);
                    }

                    document.getElementById("previousImageButton").blur();


                });

                function goToImage(){
                    saveCurrentAnnotations();

                    let index = -1;

                    try{
                        index = parseInt($("#goToImageInput").val());
                        index = index - 1; // acount for 0 indexing
                    }
                    catch(err){
                        return;
                    }

                    if(index >= 0 && index < images_data.length){
                        currentImageIndex = index;
                        annotateImage(currentImageIndex);
                    }
                }

                $("#goToImageButton").click(function(){

                    document.getElementById("goToImageButton").blur();

                    goToImage();

                });
                document.getElementById("goToImageInput").addEventListener('keyup', ({key}) => {
                    if (key == "Enter"){

                        document.getElementById("goToImageInput").blur();
                        goToImage();
                    }
                });

                // Allow the annotations to be downloaded
                $("#exportAnnos").click(function(){

                    saveCurrentAnnotations();

                    let annos = [];
                    images_data.forEach(image_info => {
                        annos = annos.concat(image_id_to_annotations[image_info.id]);
                    });

                    console.log("Exporting " + annos.length + " annotations");
                    console.log(annos);

                    var dataStr = "data:text/json;charset=utf-8," + encodeURIComponent(JSON.stringify(annos));
                    var downloadAnchorNode = document.createElement('a');
                    downloadAnchorNode.setAttribute("href",     dataStr);
                    downloadAnchorNode.setAttribute("download", annotation_file_prefix + "annotations.json");
                    document.body.appendChild(downloadAnchorNode); // required for firefox
                    downloadAnchorNode.click();
                    downloadAnchorNode.remove();

                    alert("Exported a total of " + annos.length + " annotations");

                    document.getElementById("exportAnnos").blur();

                });

                // HACK: trying to make the spacebar play the audio after modifying an annotation
                // this seems to be working....
                document.addEventListener("mouseup", (e) => {
                    if (document.activeElement) {
                        if (!(e.target.tagName.toUpperCase() == 'INPUT')){
                            document.activeElement.blur();
                        }
                    }
                });

                // Kick everything off.
                annotateImage(currentImageIndex);

            }

            // Parse the category ids provided by the user.
            function getQuickAccessCategoryIDs(){

                let rawCatIDs = $.trim(document.getElementById("easyAccessCategories").value);
                var cat_ids = []
                if (rawCatIDs != ""){
                    str_cat_ids = rawCatIDs.split(/\r?\n/);

                    let usestrIDs = document.getElementById("categoryIDTypeRadioStr").checked;
                    if (usestrIDs){
                        cat_ids = str_cat_ids;
                    }
                    else{
                        cat_ids = str_cat_ids.map(cat_id => { return parseInt(cat_id)});
                    }

                }

                return cat_ids;

            }

            /*  Allows the user to choose a directory.
             *
             */
            let i = document.querySelector('#customFile').addEventListener('change', (ev)=>{

                ev.preventDefault()

                var local_image_data = [];

                var image_json_promise = null;
                var category_json_promise = null;
                var annotation_json_promise = null;
                var config_json_promise = null;

                for(let i = 0; i < ev.target.files.length; i++){

                    let item = ev.target.files[i];

                    // Is this an image?
                    if (item.type == "image/jpeg" || item.type == "image/png"){

                        let image_id = item.name.split('.')[0];

                        local_image_data.push({
                            id : image_id,
                            url: item.webkitRelativePath,
                            attribution : "N/A"
                        });

                    }

                    // Is this a json file?
                    else if(item.type == "application/json"){


                        if (item.name == 'images.json'){
                            image_json_promise = item.text().then(text => { return JSON.parse(text) });
                        }

                        else if (item.name == 'categories.json'){

                            category_json_promise = item.text().then(text => { return JSON.parse(text) });

                        }

                        else if (item.name.includes('annotations.json')){

                            annotation_json_promise = item.text().then(text => { return JSON.parse(text) });

                        }

                        else if (item.name == 'config.json'){

                            config_json_promise = item.text().then(text => {return JSON.parse(text) } );

                        }

                        else{
                            console.log("Ignoring " + item.name + " (not sure what to do with it).")
                        }

                    }

                    else{
                        console.log("Ignoring " + item.name + " (not sure what to do with it).")
                    }

                }

                // Wait for all the file loading to finish
                Promise.all([image_json_promise, category_json_promise, annotation_json_promise, config_json_promise]).then(
                    ([image_data, category_data, annotation_data, config_data]) => {


                        if (local_image_data.length > 0 && image_data != null){
                            alert("ERROR: Found image files (jpgs/ pngs) and an images.json file. Not sure which to use! Please remove one or the other.");
                            return;
                        }

                        if (local_image_data.length > 0){
                            image_data = local_image_data;

                            // If we loaded in images from the file system, then assume we should sort by filename
                            image_data.sort(function(a, b) {
                                var nameA = a.url.toUpperCase(); // ignore upper and lowercase
                                var nameB = b.url.toUpperCase(); // ignore upper and lowercase
                                if (nameA < nameB) {
                                    return -1;
                                }
                                if (nameA > nameB) {
                                    return 1;
                                }

                                // names must be equal
                                return 0;
                            });

                        }

                        if (category_data == null){
                            alert("Didn't find a category.json file. This needs to be created.");
                            return;
                        }

                        // Did we find any existing annotations for the images?
                        if (annotation_data == null){
                            annotation_data = [];
                        }

                        // Did the user specify any quick access category ids?
                        let quickAccessCatIDs = getQuickAccessCategoryIDs();

                        // Did we get a config file?
                        const default_config = {
                            "annotationFilePrefix" : "",
                            "quickAccessCategoryIDs" : quickAccessCatIDs,
                        }
                        if (config_data != null){

                            // Try to merge the quick access category ids
                            let mergedCategoryIds = null;
                            if("quickAccessCategoryIDs" in config_data && config_data.quickAccessCategoryIDs.length > 0){
                                if (default_config.quickAccessCategoryIDs.length > 0){

                                    let a = default_config.quickAccessCategoryIDs;
                                    let b = config_data.quickAccessCategoryIDs;
                                    mergedCategoryIds = a.concat(b.filter((item) => a.indexOf(item) < 0));

                               }
                            }
                            config_data = Object.assign({}, default_config, config_data);

                            if (mergedCategoryIds != null){
                                config_data.quickAccessCategoryIDs = mergedCategoryIds;
                            }
                        }
                        else{
                            config_data = default_config;
                        }

                        // Hide the directory chooser form, and show the annotation task
                        document.getElementById("dirChooser").hidden = true;
                        document.getElementById("annotationTask").hidden = false;

                        startAnnotating(image_data, category_data, annotation_data, config_data);

                    });

            });

            // Try to make sure the user is in Chrome
            // See here: https://stackoverflow.com/a/13348618/11337608

            // please note,
            // that IE11 now returns undefined again for window.chrome
            // and new Opera 30 outputs true for window.chrome
            // but needs to check if window.opr is not undefined
            // and new IE Edge outputs to true now for window.chrome
            // and if not iOS Chrome check
            // so use the below updated condition
            var isChromium = window.chrome;
            var winNav = window.navigator;
            var vendorName = winNav.vendor;
            var isOpera = typeof window.opr !== "undefined";
            var isIEedge = winNav.userAgent.indexOf("Edge") > -1;
            var isIOSChrome = winNav.userAgent.match("CriOS");

            if (isIOSChrome) {
            // is Google Chrome on IOS
                alert("This tool is not tested for iOS environments")

            } else if(
            isChromium !== null &&
            typeof isChromium !== "undefined" &&
            vendorName === "Google Inc." &&
            isOpera === false &&
            isIEedge === false
            ) {
            // is Google Chrome
            } else {
            // not Google Chrome
                alert("This tool needs to be opened with Google Chrome.")
            }

        </script>

    </body>
</html>